import flet as ft
import requests
import threading
import time
from datetime import datetime
import logging

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³Ø¬Ù„Ø§Øª ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Ø§Ù„Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø­Ø³Ø¨ Ø·Ù„Ø¨Ùƒ) ---
DEFAULT_LAPTOP_IP = "192.168.1.6"  # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ø§Ø¨ØªÙˆØ¨
DEFAULT_TERMUX_IP = "127.0.0.1"    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ø­Ù„ÙŠ Ù„Ù„Ù‡Ø§ØªÙ
DEFAULT_FAST_MODEL = "qwen:0.5b"
DEFAULT_SMART_MODEL = "gemma:2b"
DEFAULT_THINKER_REMOTE = "qwen2.5:4b"

# --- Ø·Ø¨Ù‚Ø© Ø§Ù„Ø´Ø¨ÙƒØ© (Network Layer) ---
class AIConnector:
    @staticmethod
    def ping_server(url_base):
        """ÙØ­Øµ Ø³Ø±ÙŠØ¹ Ù„Ù„Ø§ØªØµØ§Ù„ (Health Check)"""
        try:
            if not url_base.startswith("http"): url_base = f"http://{url_base}"
            # Ù†Ø±Ø³Ù„ Ø·Ù„Ø¨ Ø®ÙÙŠÙ Ù„Ù„Ø¬Ø°Ø±
            requests.get(f"{url_base}:11434", timeout=1)
            return True
        except:
            return False

    @staticmethod
    def send_request(url_base, model, prompt, timeout):
        try:
            if not url_base.startswith("http"): url_base = f"http://{url_base}"
            url = f"{url_base}:11434/api/generate"
            payload = {"model": model, "prompt": prompt, "stream": False, "options": {"num_ctx": 4096}}
            
            logging.info(f"Connecting to {url}...")
            response = requests.post(url, json=payload, timeout=timeout)
            response.raise_for_status()
            return True, response.json().get("response", "")
        except requests.exceptions.Timeout:
            return False, "âš ï¸ Ø§Ù„Ù…Ù‡Ù„Ø© Ø§Ù†ØªÙ‡Øª! Ø§Ù„Ø®Ø§Ø¯Ù… Ù„Ù… ÙŠØ³ØªØ¬Ø¨ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø­Ø¯Ø¯."
        except requests.exceptions.ConnectionError:
            return False, "âŒ ØªØ¹Ø°Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ 'ollama serve' ÙˆÙ…Ù† ØµØ­Ø© Ø§Ù„Ù€ IP."
        except Exception as e:
            return False, f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}"

def main(page: ft.Page):
    # --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ---
    page.title = "AI Nexus V2.1"
    page.theme_mode = ft.ThemeMode.DARK
    page.bgcolor = "#0e0e0e"
    page.padding = 0

    # --- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø© (State Management) ---
    termux_led = ft.Icon(name=ft.Icons.CIRCLE, color=ft.Colors.RED_900, size=12)
    laptop_led = ft.Icon(name=ft.Icons.CIRCLE, color=ft.Colors.RED_900, size=12)
    
    # Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
    stored_laptop = page.client_storage.get("laptop_ip")
    stored_termux = page.client_storage.get("termux_ip")
    
    # Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (Text Fields)
    laptop_ip_input = ft.TextField(label="Laptop IP", value=stored_laptop if stored_laptop else DEFAULT_LAPTOP_IP, border_color=ft.Colors.BLUE_400)
    termux_ip_input = ft.TextField(label="Termux IP (Local)", value=stored_termux if stored_termux else DEFAULT_TERMUX_IP, border_color=ft.Colors.GREEN_400)
    
    fast_model_input = ft.TextField(label="Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø±ÙŠØ¹", value=page.client_storage.get("fast_model") or DEFAULT_FAST_MODEL, text_size=12)
    smart_model_input = ft.TextField(label="Ø§Ù„Ù…ÙÙƒØ± Ø§Ù„Ù…Ø­Ù„ÙŠ", value=page.client_storage.get("smart_model") or DEFAULT_SMART_MODEL, text_size=12)
    remote_model_input = ft.TextField(label="Ø§Ù„Ù…ÙÙƒØ± Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚", value=page.client_storage.get("remote_model") or DEFAULT_THINKER_REMOTE, text_size=12)

    # --- Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø´Ø¨ÙƒØ© (Background Thread) ---
    def health_check_loop():
        while True:
            # Ù†Ø¬Ù„Ø¨ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù…Ø¨Ø§Ø´Ø±Ø©
            # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù‚ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ù…Ù† Ø®ÙŠØ· Ø¢Ø®Ø± Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø®Ø·Ø±Ø§Ù‹ØŒ Ù„Ø°Ø§ Ù†Ø³ØªØ®Ø¯Ù… try
            try:
                t_ip = termux_ip_input.value
                l_ip = laptop_ip_input.value
                
                # ØªØ­Ø¯ÙŠØ« Termux LED
                if AIConnector.ping_server(t_ip):
                    termux_led.color = ft.Colors.GREEN_ACCENT_400
                    termux_led.tooltip = "Termux: Ù…ØªØµÙ„"
                else:
                    termux_led.color = ft.Colors.RED_900
                    termux_led.tooltip = "Termux: ØºÙŠØ± Ù…ØªØµÙ„"

                # ØªØ­Ø¯ÙŠØ« Laptop LED
                if AIConnector.ping_server(l_ip):
                    laptop_led.color = ft.Colors.BLUE_ACCENT_400
                    laptop_led.tooltip = "Laptop: Ù…ØªØµÙ„"
                else:
                    laptop_led.color = ft.Colors.RED_900
                    laptop_led.tooltip = "Laptop: ØºÙŠØ± Ù…ØªØµÙ„"
                
                page.update()
            except Exception as e:
                logging.error(f"Health Check Error: {e}")
            
            time.sleep(8) # ÙØ­Øµ ÙƒÙ„ 8 Ø«ÙˆØ§Ù†ÙŠ

    threading.Thread(target=health_check_loop, daemon=True).start()

    # --- Ù†Ø§ÙØ°Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (The Dialog) ---
    def close_settings(e):
        page.close(settings_dialog)

    def save_settings(e):
        page.client_storage.set("laptop_ip", laptop_ip_input.value)
        page.client_storage.set("termux_ip", termux_ip_input.value)
        page.client_storage.set("fast_model", fast_model_input.value)
        page.client_storage.set("smart_model", smart_model_input.value)
        page.client_storage.set("remote_model", remote_model_input.value)
        
        page.close(settings_dialog)
        page.snack_bar = ft.SnackBar(content=ft.Text("ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„Ø´Ø¨ÙƒØ©"), bgcolor=ft.Colors.GREEN)
        page.open(page.snack_bar)
        page.update()

    # Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†Ø§ÙØ°Ø©
    settings_content = ft.Column([
        ft.Text("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„", weight=ft.FontWeight.BOLD, color=ft.Colors.BLUE_200),
        laptop_ip_input,
        termux_ip_input,
        ft.Divider(),
        ft.ExpansionTile(
            title=ft.Text("ØªØ®ØµÙŠØµ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬", size=14),
            leading=ft.Icon(ft.Icons.MEMORY, color=ft.Colors.GREY_400),
            controls=[
                ft.Container(
                    content=ft.Column([fast_model_input, smart_model_input, remote_model_input], spacing=10),
                    padding=10
                )
            ]
        )
    ], height=400, width=300, scroll=ft.ScrollMode.AUTO)

    settings_dialog = ft.AlertDialog(
        modal=True,
        title=ft.Text("Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…"),
        content=settings_content,
        actions=[
            ft.TextButton("Ø¥Ù„ØºØ§Ø¡", on_click=close_settings),
            ft.ElevatedButton("Ø­ÙØ¸", on_click=save_settings, bgcolor=ft.Colors.BLUE_600, color=ft.Colors.WHITE),
        ],
        actions_alignment=ft.MainAxisAlignment.END,
    )

    def open_settings(e):
        page.open(settings_dialog)

    # --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Chat UI) ---
    chat_list = ft.ListView(expand=True, spacing=10, padding=20, auto_scroll=True)
    loading_indicator = ft.ProgressBar(width=None, color=ft.Colors.CYAN_300, bgcolor=ft.Colors.TRANSPARENT, visible=False)

    def add_chat_bubble(text, sender="user", is_error=False):
        align = ft.MainAxisAlignment.END if sender == "user" else ft.MainAxisAlignment.START
        if sender == "user":
            bg_color = ft.Colors.BLUE_800
        elif is_error:
            bg_color = ft.Colors.RED_900
        else:
            bg_color = ft.Colors.GREY_800

        bubble = ft.Container(
            content=ft.Markdown(text, selectable=True, extension_set="standard"),
            padding=15,
            border_radius=ft.border_radius.only(
                top_left=15, top_right=15, 
                bottom_left=15 if sender == "user" else 0,
                bottom_right=0 if sender == "user" else 15
            ),
            bgcolor=bg_color,
            # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø±Ø¶ Ø£Ù‚ØµÙ‰ Ù„Ø¬Ù…Ø§Ù„ÙŠØ© Ø§Ù„ÙÙ‚Ø§Ø¹Ø©
            width=300 if len(text) > 50 else None, 
        )
        chat_list.controls.append(ft.Row([bubble], alignment=align))
        page.update()

    # --- Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (The Core Logic) ---
    def process_request(prompt):
        loading_indicator.visible = True
        page.update()
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ø­Ø¸Ø© Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
        l_ip = laptop_ip_input.value
        t_ip = termux_ip_input.value
        fast_m = fast_model_input.value
        smart_m = smart_model_input.value
        remote_m = remote_model_input.value

        response_text = ""
        is_error = False
        lower_prompt = prompt.lower()
        
        # 1. Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ¹
        if "Ø³Ø§Ø¹Ø©" in lower_prompt or "ØªØ§Ø±ÙŠØ®" in lower_prompt:
            response_text = f"â° {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        
        # 2. Ù…Ø³Ø§Ø± Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚
        elif any(k in prompt for k in ["ÙÙƒØ±", "Ø¨Ø¹Ù…Ù‚", "Ø®Ø·Ø·", "ØªØ­Ù„ÙŠÙ„"]):
            success, resp = AIConnector.send_request(
                l_ip, remote_m, 
                f"Ø£Ù†Øª Ù…Ù‡Ù†Ø¯Ø³ Ø®Ø¨ÙŠØ±. ÙÙƒØ± Ø¨Ø¹Ù…Ù‚ ÙˆØªÙØµÙŠÙ„ Ù…Ù…Ù„. Ø§Ù„Ø³Ø¤Ø§Ù„: {prompt}", 300
            )
            if success:
                response_text = f"ğŸ§  **(Ø§Ù„Ù…ÙÙƒØ± Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚):**\n\n{resp}"
            else:
                response_text += f"âš ï¸ **ÙØ´Ù„ Ø§Ù„Ù„Ø§Ø¨ØªÙˆØ¨ØŒ Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ÙÙƒØ± Ø§Ù„Ù…Ø­Ù„ÙŠ...**\n\n"
                success_local, resp_local = AIConnector.send_request(
                    t_ip, smart_m, 
                    f"ÙÙƒØ± Ø¨Ø¹Ù…Ù‚: {prompt}", 120
                )
                if success_local:
                    response_text += f"ğŸ“± **(Ø§Ù„Ù…ÙÙƒØ± Ø§Ù„Ù…Ø­Ù„ÙŠ):**\n{resp_local}"
                else:
                    response_text += f"âŒ **ÙØ´Ù„ ÙƒÙ„ÙŠ:** {resp_local}"
                    is_error = True
        
        # 3. Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø¹Ø§Ø¯ÙŠ
        else:
            success, resp = AIConnector.send_request(t_ip, fast_m, prompt, 60)
            if success:
                response_text = resp
            else:
                response_text = f"âŒ Ø®Ø·Ø£ Ù…Ø­Ù„ÙŠ: {resp}"
                is_error = True

        loading_indicator.visible = False
        add_chat_bubble(response_text, "bot", is_error)

    def on_send_click(e):
        prompt = input_field.value
        if not prompt: return
        input_field.value = ""
        add_chat_bubble(prompt, "user")
        threading.Thread(target=process_request, args=(prompt,), daemon=True).start()
        input_field.focus()

    # --- ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ---
    input_field = ft.TextField(
        hint_text="ØªØ­Ø¯Ø« Ù…Ø¹ Ù…Ø³Ø§Ø¹Ø¯Ùƒ...",
        border_radius=30,
        bgcolor=ft.Colors.GREY_900,
        border_color=ft.Colors.TRANSPARENT,
        expand=True,
        on_submit=on_send_click
    )

    page.appbar = ft.AppBar(
        title=ft.Row([
            ft.Text("AI Hybrid", weight=ft.FontWeight.BOLD),
            ft.Container(width=10),
            ft.Tooltip(message="Ø­Ø§Ù„Ø© Termux", content=termux_led),
            ft.Tooltip(message="Ø­Ø§Ù„Ø© Laptop", content=laptop_led),
        ]),
        bgcolor=ft.Colors.GREY_900,
        actions=[ft.IconButton(ft.Icons.SETTINGS, on_click=open_settings)],
    )

    page.add(
        ft.Column([
            chat_list,
            ft.Container(loading_indicator, height=5),
            ft.Container(
                content=ft.Row([
                    input_field,
                    ft.FloatingActionButton(icon=ft.Icons.SEND, on_click=on_send_click, bgcolor=ft.Colors.BLUE_600)
                ]),
                padding=10,
                bgcolor=ft.Colors.GREY_950
            )
        ], expand=True)
    )

ft.app(target=main)